# Multi-modalSensorDataCollection
The goal of this assignment is to get familiar with the smartphone’s multi-modal sensing capability. This assignment will introduce you to the smartphone’s development environment through a real life coding exercise.

Team Members : [Abrar Ahmed Mohammed] & [Richa Kulkarni]

Stage1: Collected the raw sensor data in real time and store them in a csv file in the smartphone. #The CSV files have been submitted as .ZIP

Stage2: The activities such as IDLE, WALKING, RUNNING, JUMPING, TAKING STAIRS have been performed with the mobile phone held by two hands, screen facing up and directing the phone’s y-axis towards the direction that you are facing.

Stage3: Pedometer has been implemented without the use of in-built sensor and it works just fine with (+-)1-2 steps error.

Stage4: 3D graphs are plotted in .ipynb notebook

Stage5: Pushed real-time data stream to FIREBASE REAL-TIME DATABASE and stored it.

PLOTS:

![image](https://user-images.githubusercontent.com/56755432/197374160-45f30ec0-c74b-41cf-8cd4-2af2615ad08d.png)

![image](https://user-images.githubusercontent.com/56755432/197374180-3f632e24-9fad-45ac-9d6a-c43b255b0f45.png)

![image](https://user-images.githubusercontent.com/56755432/197374184-e2701f6c-52c8-4f1e-abac-867920a72bac.png)

![image](https://user-images.githubusercontent.com/56755432/197374191-ff625b89-61fe-416d-9276-f08558bbbd6c.png)


